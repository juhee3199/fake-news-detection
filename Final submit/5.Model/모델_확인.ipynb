{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모델 확인",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3LcHWdoaKXK"
      },
      "source": [
        "#**Model**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwAQw1o2Av2C"
      },
      "source": [
        "# konlpy Mecab 사용하기\r\n",
        "\r\n",
        "!set -x \\\r\n",
        "&& pip install konlpy \\\r\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxp2JcmbNN_l",
        "outputId": "33b48a3c-ca10-430e-d481-bb1975a953f8"
      },
      "source": [
        "# 내 드라이브에 대한 주소\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH9XAIwVNM6i"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import joblib\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR74GZMCBBuz"
      },
      "source": [
        "# 내 드라이브에 대한 주소\r\n",
        "path = \"/gdrive//My Drive/dacon_news/\"\r\n",
        "\r\n",
        "train = pd.read_csv(path + \"data/news_train.csv\")\r\n",
        "test = pd.read_csv(path + \"data/news_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o346VrtzZatW"
      },
      "source": [
        "# content 맨앞이 [이거나 (이거나 제목이면 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcwUcZBRVEvd"
      },
      "source": [
        "train[\"content_startswith_[\"]=train.content.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\") or str(x).startswith(\"제목\"))+0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upG2RgbFWdeb"
      },
      "source": [
        "# 타이틀을 이용한 feature\r\n",
        "- 해당 title에 몇가지 단어가 들어갈 경우 약 90% 이상이 info가 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOIXetvBV--H"
      },
      "source": [
        "title_noise = ['적중 100%', '글로벌 주요 뉴스', '[전문가 의견]', \r\n",
        "               '[포커스]', '※','■', '★',' TOP', 'BEST',\r\n",
        "'전문가의 눈', '전문가선정', '전문가의견','】','후속주도 감사합니다',\r\n",
        "               '전문가추천', '주요이슈']\r\n",
        "\r\n",
        "def title_choose(x):\r\n",
        "  if (\"종목\" in x[-6:]) or (\"관련주\" in x[-5:]):\r\n",
        "    return 1\r\n",
        "  for noise in title_noise:\r\n",
        "    if noise in x.upper():\r\n",
        "        return 1\r\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpT_MW-019mj"
      },
      "source": [
        "train[\"info1_title\"]=train['title'].apply(title_choose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP_h-HL7RmvU"
      },
      "source": [
        "# content를 이용한 feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlrmrsR1RqCo"
      },
      "source": [
        "content_noise = ['00%','긴급공개', '긴급 공개','임상3상','# ','대장株','대장주','카톡','원\"만','TOP','BEST']\r\n",
        "\r\n",
        "def content_choose(x):\r\n",
        "  if (x=='관련기사') or (x==\"관련 테마분석\") or (x==\"코스피\") or (x==\"코스닥\"):\r\n",
        "    return 1\r\n",
        "  for noise in content_noise:\r\n",
        "    if noise in x.upper():\r\n",
        "        return 1\r\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWoQmRopTf79"
      },
      "source": [
        "train[\"info1_content\"]=train[\"content\"].apply(content_choose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbS7TN-xgARn"
      },
      "source": [
        "# Order을 이용한 feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5Tf50Emf-39"
      },
      "source": [
        "title_group = (train.groupby([\"title\"]).count())[\"n_id\"]\r\n",
        "train[\"new_ord\"]=train.apply(lambda x: x[\"ord\"]/title_group[x[\"title\"]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TOb5PyeZc40"
      },
      "source": [
        "# tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9C_faJHpBB8"
      },
      "source": [
        "from konlpy.tag import Mecab\r\n",
        "import re\r\n",
        "\r\n",
        "def text_preprocessing(text_list):\r\n",
        "\r\n",
        "    tokenizer = Mecab() #형태소 분석기\r\n",
        "\r\n",
        "    token_list = [] \r\n",
        "    \r\n",
        "    for text in text_list:\r\n",
        "        txt = re.sub(\"[a-zA-Z0-9]\", ' ', text) #영문, 숫자 제거 -> 특수문자는 제거하지 않음\r\n",
        "        txt = re.sub('[가-힣]+\\s기자','기자', txt) #기자 이름 제거\r\n",
        "        token = tokenizer.morphs(txt) #형태소 분석\r\n",
        "\r\n",
        "        token = [t for t in token] \r\n",
        "        token_list.append(token)\r\n",
        "        \r\n",
        "    return token_list, tokenizer\r\n",
        "\r\n",
        "#형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문입니다.\r\n",
        "train['new_article'], mecab = text_preprocessing(train['content'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fJgEe3joxSc"
      },
      "source": [
        "# 결측치 제거\r\n",
        "train = train[train[\"new_article\"].apply(lambda x: False if len(x)==0 else True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyht3PbGT7SR"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5O1nOzRK2AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbe62d2-8830-47e1-eff6-e1b30a21bc71"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "max_len = 100\r\n",
        "\r\n",
        "def text2sequence(train_text, max_len=100):\r\n",
        "    \r\n",
        "    tokenizer = Tokenizer()\r\n",
        "    tokenizer.fit_on_texts(train_text)\r\n",
        "    train_X_seq = tokenizer.texts_to_sequences(train_text)\r\n",
        "    vocab_size = len(tokenizer.word_index) + 1\r\n",
        "    print('vocab_size : ', vocab_size)\r\n",
        "    X_train = pad_sequences(train_X_seq, maxlen = max_len, truncating=\"pre\") # 길이를 맞춰줌\r\n",
        "    return X_train, vocab_size, tokenizer\r\n",
        "\r\n",
        "train_y = train['info']\r\n",
        "train_X, vocab_size, vectorizer = text2sequence(train['new_article'], max_len = max_len)\r\n",
        "\r\n",
        "print(train_X.shape, train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size :  33519\n",
            "(118676, 100) (118676,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doN8XRIpJQ8h",
        "outputId": "679a89dd-aa2a-4e0c-c386-ccde19e6fb79"
      },
      "source": [
        "# vectorizer 저장\r\n",
        "joblib.dump(vectorizer, \"vectorizer.sav\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E9L7Gp6HcxM"
      },
      "source": [
        "#train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoqDYSIMXgSE"
      },
      "source": [
        "#concat\r\n",
        "feature_num = 4\r\n",
        "train_X = np.concatenate([train_X,train[[\"info1_title\",\"info1_content\",\"new_ord\",\"content_startswith_[\"]].values.reshape(-1,feature_num)], axis=1)\r\n",
        "\r\n",
        "# 문장별로 train_test set 분리\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, random_state = 42, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw67R_ABRslw"
      },
      "source": [
        "# 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpGqkEngNbOa"
      },
      "source": [
        "# EDA기반으로 만든 feature 예측변수로 추가한 모델 생성\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "def LSTM_add_feature(vocab_size, embedding_size = 100, max_len=100):\r\n",
        "  input1 = keras.layers.Input(shape = [max_len,]) #문장 단어 input\r\n",
        "  input2 = keras.layers.Input(shape = [feature_num,]) # EDA기반 feature input\r\n",
        "\r\n",
        "  # LSTM\r\n",
        "  embedding = keras.layers.Embedding(vocab_size, embedding_size, input_length = max_len)(input1) # 임베딩 가중치 훈련\r\n",
        "  dropout1 = keras.layers.SpatialDropout1D(0.5)(embedding)\r\n",
        "  lstm1 = keras.layers.LSTM(32, return_sequences = True)(dropout1)\r\n",
        "  lstm2 = keras.layers.LSTM(32)(lstm1)\r\n",
        "  dropout2 = keras.layers.Dropout(0.5)(lstm2)\r\n",
        "\r\n",
        "  # MLP\r\n",
        "  concat = keras.layers.concatenate([dropout2,input2])\r\n",
        "  hidden = keras.layers.Dense(32, activation = \"selu\")(concat)\r\n",
        "  output = keras.layers.Dense(1, activation = \"sigmoid\")(hidden)\r\n",
        "\r\n",
        "  model = keras.Model(inputs = [input1, input2], outputs = [output])\r\n",
        "\r\n",
        "  model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=\"binary_crossentropy\", metrics = \"accuracy\")\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgFdGl1YRzQr"
      },
      "source": [
        "# 모델 훈련 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLyta-R27x7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ba563a-29e0-4358-8e64-85738453ce3e"
      },
      "source": [
        "# 훈련 시\r\n",
        "tf.random.set_seed(42)\r\n",
        "embedding_size = 300\r\n",
        "\r\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"hyerim_add_feature_best_model2.h5\",\r\n",
        "                                               save_best_only = True)\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "max_epoch = 3\r\n",
        "batch_size = 32\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "model = LSTM_add_feature(vocab_size, max_len = max_len, embedding_size = embedding_size)\r\n",
        "history = model.fit(x=[X_train[:,:max_len],X_train[:,-feature_num:]], y=y_train, epochs=max_epoch,\r\n",
        "                batch_size = batch_size,  validation_data = ((X_valid[:,:max_len],X_valid[:,-feature_num:]),y_valid), validation_batch_size = batch_size,\r\n",
        "                 callbacks = [checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 300)     10055700    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 100, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 100, 32)      42624       spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 32)           8320        lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32)           0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 36)           0           dropout_1[0][0]                  \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           1184        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            33          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 10,107,861\n",
            "Trainable params: 10,107,861\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/3\n",
            "2597/2597 [==============================] - 264s 101ms/step - loss: 0.0920 - accuracy: 0.9653 - val_loss: 0.0230 - val_accuracy: 0.9921\n",
            "Epoch 2/3\n",
            "2597/2597 [==============================] - 266s 102ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0207 - val_accuracy: 0.9931\n",
            "Epoch 3/3\n",
            "2597/2597 [==============================] - 265s 102ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0259 - val_accuracy: 0.9923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUSGWJvkDgiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "13c7bc51-583f-44dc-89a8-17078a5427e9"
      },
      "source": [
        "best_model = keras.models.load_model(\"hyerim_add_feature_best_model2.h5\") # 저장된 모델 불러오기\r\n",
        "plt.plot(pd.DataFrame(history.history)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb214d70a90>,\n",
              " <matplotlib.lines.Line2D at 0x7fb214d70ba8>,\n",
              " <matplotlib.lines.Line2D at 0x7fb214d70cf8>,\n",
              " <matplotlib.lines.Line2D at 0x7fb214d70e48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3X-721afCH9",
        "outputId": "bc5f9ce5-c415-4dd2-daa7-1a56240c12fc"
      },
      "source": [
        "# 성능\r\n",
        "best_model.evaluate((X_valid[:,:max_len],X_valid[:,-feature_num:]),y_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1113/1113 [==============================] - 8s 7ms/step - loss: 0.0207 - accuracy: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.020706063136458397, 0.9930904507637024]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTGrQTG0_DcA"
      },
      "source": [
        "# 모델 최종 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-Kb3yW4JeQ",
        "outputId": "b4604fcb-bdec-4b21-992f-21fd266bd126"
      },
      "source": [
        "# 실제 예측시\r\n",
        "# 학습속도를 높이기 위한 index 재정렬\r\n",
        "index_seq = (train_X.argmax(axis=1)).argsort(axis=0)\r\n",
        "sort_train_X = train_X[index_seq]\r\n",
        "sort_train_y = train_y.iloc[index_seq]\r\n",
        "\r\n",
        "tf.random.set_seed(2020)\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "max_epoch = 2\r\n",
        "batch_size = 32\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "model = LSTM_add_feature(vocab_size, max_len = max_len, embedding_size = embedding_size)\r\n",
        "history = model.fit(x=[sort_train_X[:,:-feature_num],sort_train_X[:,-feature_num:]], y=sort_train_y,epochs=max_epoch,batch_size = batch_size)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_65 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_28 (Embedding)        (None, 100, 300)     10055700    input_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_28 (SpatialDr (None, 100, 300)     0           embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_56 (LSTM)                  (None, 100, 32)      42624       spatial_dropout1d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_57 (LSTM)                  (None, 32)           8320        lstm_56[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 32)           0           lstm_57[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_66 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 36)           0           dropout_28[0][0]                 \n",
            "                                                                 input_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_64 (Dense)                (None, 32)           1184        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_65 (Dense)                (None, 1)            33          dense_64[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 10,107,861\n",
            "Trainable params: 10,107,861\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "3709/3709 [==============================] - 381s 102ms/step - loss: 0.0759 - accuracy: 0.9713\n",
            "Epoch 2/2\n",
            "3709/3709 [==============================] - 377s 102ms/step - loss: 0.0125 - accuracy: 0.9961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laEwou3JphOQ"
      },
      "source": [
        "# lstm 모델 저장\r\n",
        "model.save(\"lstm_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwVlY_L6oFw4"
      },
      "source": [
        "# 전문장, 전전문장의 예측결과값을 이용하여 예측값 보정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AYUPwxlrcI1"
      },
      "source": [
        "lstm_model = keras.models.load_model(\"lstm_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfCyi7aR2kDS"
      },
      "source": [
        "# LSTM을 통한 예측\r\n",
        "train_predicted = lstm_model.predict((train_X[:,:max_len],train_X[:,-feature_num:]))\r\n",
        "\r\n",
        "# 각 문장의 바로 앞문장과, 그 앞 문장의 예측값 생성\r\n",
        "train_pre_predicted1 = np.array([train_predicted[idx-1][0] for idx in range(len(train_predicted))]).reshape(-1,1) # 앞문장\r\n",
        "train_pre_predicted2 = np.array([train_predicted[idx-2][0] for idx in range(len(train_predicted))]).reshape(-1,1) # 앞앞문장\r\n",
        "\r\n",
        "# 학습을 위한 데이터셋 생성\r\n",
        "train[\"predicted\"]=train_predicted\r\n",
        "train[\"pre_predicted1\"]=train_pre_predicted1\r\n",
        "train[\"pre_predicted2\"]=train_pre_predicted2\r\n",
        "\r\n",
        "# ord가 1,2 인 것은 학습에서 제외 후 최종 lgbm 훈련을 위한 데이터셋 생성\r\n",
        "final_X = train[[\"predicted\",\"pre_predicted1\",\"pre_predicted2\"]][(train[\"ord\"]!=1)&(train[\"ord\"]!=2)]\r\n",
        "final_y = train[\"info\"][(train[\"ord\"]!=1)&(train[\"ord\"]!=2)]\r\n",
        "final_X_train, final_X_valid, final_y_train, final_y_valid = train_test_split(final_X, final_y,test_size = 0.3, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to4KDsxX0lbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a3b2af-8137-4801-8332-2230ef934af2"
      },
      "source": [
        "# LGBM 모델 불러오기\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "\r\n",
        "# index 랜덤으로 섞음\r\n",
        "np.random.seed(42)\r\n",
        "random_index = np.random.randint(0,len(final_X),len(final_X))\r\n",
        "\r\n",
        "# LGBM model 예측\r\n",
        "lgbm_model=LGBMClassifier(random_state=42)\r\n",
        "lgbm_model.fit(final_X.iloc[random_index], y=final_y.iloc[random_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE1pP6Nvo71w",
        "outputId": "2b337bb6-44e4-457e-b605-16b58ddc2479"
      },
      "source": [
        "# lgbm 모델 저장\r\n",
        "joblib.dump(lgbm_model, 'lgbm_model.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lgbm_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDjRKT6a_Tx3"
      },
      "source": [
        "# test 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efZxw2tUiMfr"
      },
      "source": [
        "path = \"/gdrive/My Drive/dacon_news/\"\r\n",
        "feature_num = 4\r\n",
        "test = pd.read_csv(path+\"data/news_test.csv\")\r\n",
        "\r\n",
        "# EDA 기반 feature 추가\r\n",
        "test[\"info1_title\"]=test[\"title\"].apply(title_choose)\r\n",
        "test[\"info1_content\"]=test[\"content\"].apply(content_choose)\r\n",
        "test[\"content_startswith_[\"]=test.content.apply(lambda x : str(x).startswith(\"[\") or str(x).startswith(\"(\") or str(x).startswith(\"제목\"))+0\r\n",
        "title_group = (test.groupby([\"title\"]).count())[\"n_id\"]\r\n",
        "test[\"new_ord\"]=test.apply(lambda x: x[\"ord\"]/title_group[x[\"title\"]], axis=1)\r\n",
        "\r\n",
        "# 전처리\r\n",
        "test['new_article'], okt = text_preprocessing(test['content'])\r\n",
        "test_X_seq = vectorizer.texts_to_sequences(test[\"new_article\"])\r\n",
        "test_X = pad_sequences(test_X_seq, maxlen = max_len) # 길이를 맞춰줌\r\n",
        "\r\n",
        "# concat\r\n",
        "test_X = np.concatenate([test_X,test[[\"info1_title\",\"info1_content\",\"new_ord\",\"content_startswith_[\"]].values.reshape(-1,feature_num)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtfXQsVKkuAQ"
      },
      "source": [
        "# lstm 모델을 통한 예측\r\n",
        "predicted = lstm_model.predict([test_X[:,:max_len],test_X[:,-feature_num:]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ncycsgEs4jH"
      },
      "source": [
        "# 앞문장, 앞앞문장으로 최종 예측\r\n",
        "pre_predicted1 = np.array([predicted[idx-1][0] for idx in range(len(predicted))]).reshape(-1,1) # 앞문장\r\n",
        "pre_predicted2 = np.array([predicted[idx-2][0] for idx in range(len(predicted))]).reshape(-1,1) # 앞앞문장\r\n",
        "\r\n",
        "test[\"predicted\"]=predicted\r\n",
        "test[\"pre_predicted1\"]=pre_predicted1\r\n",
        "test[\"pre_predicted2\"]=pre_predicted2\r\n",
        "\r\n",
        "lgbm_final_predicted = lgbm_model.predict(test[[\"predicted\",\"pre_predicted1\",\"pre_predicted2\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eyxDj1Gts9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd442aeb-4075-4862-adfa-a6aa97d22bb0"
      },
      "source": [
        "# ord가 1,2인 것은 lstm모델만을 통해 예측, threshold 0.6으로 분류\r\n",
        "test[\"info\"]=lgbm_final_predicted\r\n",
        "test[\"info\"][test[\"ord\"]==1]=(test[\"predicted\"][test[\"ord\"]==1]>=0.6)+0\r\n",
        "test[\"info\"][test[\"ord\"]==2]=(test[\"predicted\"][test[\"ord\"]==2]>=0.6)+0\r\n",
        "test[\"info\"][test[\"content\"].apply(lambda x: True if ('http://etoday.bujane.co.kr/' in x) or ('http://bit.ly/2XrAuGJ_itoozanews' in x) or ('http://www.hisl.co.kr/0306/' in x) or ('https://www.hankyung.com/election2020/' in x) or (x==']]') else False)]=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "budSlGRTnrTs"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMgi0uZNsawr"
      },
      "source": [
        "submission = pd.read_csv(path+\"/data/sample_submission.csv\")\r\n",
        "submission.to_csv(\"submission.csv\", encoding=\"utf-8-sig\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Q7-70BR5oO"
      },
      "source": [
        "# 구글 word2vec 모델\r\n",
        "\r\n",
        "#word2vec_g = gensim.models.KeyedVectors.load_word2vec_format(path+'embedding/GoogleNews-vectors-negative300.bin.gz', binary = True)\r\n",
        "#embedding_size = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd5zy8_5fwvT"
      },
      "source": [
        "# 한국어 word2vec model\r\n",
        "#word2vec2 = gensim.models.Word2Vec.load(path+'embedding/ko.bin')\r\n",
        "#embedding_size = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVpNijXJOOm-"
      },
      "source": [
        "# glove model\r\n",
        "\"\"\"\r\n",
        "2. # load the whole embedding into memory\r\n",
        "glove = dict()\r\n",
        "embedding_size = 100\r\n",
        "f = open(path+'embedding/word-embeddings/glove/glove.txt')\r\n",
        "for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    vector = np.asarray(values[1:], dtype='float32')\r\n",
        "    glove[word] = vector\r\n",
        "f.close()\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}